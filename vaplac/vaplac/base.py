"""
This module provides the DataTaker class,
to process, validate and visualize data.

"""

import platform
from os.path import splitext, basename, dirname, realpath
from itertools import groupby
from tkinter import Tk
from tkinter.filedialog import askopenfilename, askopenfilenames
import re
import numpy as np
import pandas as pd
from math import sqrt
from copy import deepcopy

from CoolProp.CoolProp import PropsSI as refproperties, PhaseSI as phase
from CoolProp.HumidAirProp import HAPropsSI as psychro
from cerberus import Validator

from ._plot import _plot
from vaplac.xpint import UnitRegistry
from vaplac import sauroneye

class DataTaker():
    """
    Process and visualize data from files generated by a data logger.

    A DataTaker object holds information about data contained in a file
    from a data logger (CSV or excel). The filename must be passed to
    the constructor. Moreover, a DataTaker has methods to validate
    or return the data. The latter can be useful to perform
    calculations that are not implemented in the DataTaker class.

    Because column names in data files may be quite long, it becomes
    tedious if the user has to type them numerous times.
    A DataTaker object thus links those names to alternate, shorter ones
    based on an external file that can be specified (default is
    `name_conversions_UTF8.txt` on unix-based systems, and
    `name_conversions_ANSI.txt` on windows sysems). This file also
    gives the units and property for each measured quantity.

    Parameters
    ----------
    filename : str
        The name of the DataTaker file (.csv or .xlsx) to read.

    Attributes
    ----------
    read_file : str
        The name of the data file that was read by the DataTaker.
    """

    ureg = UnitRegistry()
    Q_ = ureg.Quantity
    ureg.define('fraction = [] = frac = ratio')
    ureg.define('percent = 1e-2 frac = pct')
    ureg.define('ppm = 1e-6 fraction')

    def __init__(self, filenames=None, initialdir='.', filetype=None,
                 convert_file=None, mode=None, refrigerant='R410a'):

        if convert_file is None:
            encoding = 'ANSI' if platform.system() == 'Windows' else 'UTF8'
            dir_path = dirname(realpath(__file__)) + '/..'
            convert_file = f'{dir_path}/name_conversions_{encoding}.txt'
        # assign _name_converter attribute
        self._build_name_converter(convert_file)
        self.raw_data = None
        self.read_files = []
        self.test_settings = None
        # assign read_file and raw_data attributes
        self.read(filenames, initialdir=initialdir, filetype=filetype, mode=mode)
        self.quantities = {}
        self._groups = {}
        self._set_timestep(kind='Quantity')
        self._set_timestep(kind='Timedelta')
        self._refrigerant = refrigerant
        limits = np.array([-np.inf, 1, 30, 60, np.inf]) * self.ureg('min')
        self.set_steady_state_limits(limits)

    def get_timestep(self, kind='Timedelta'):
        if kind not in ('Timedelta', 'Quantity'):
            raise ValueError("kind must be either 'Timedelta' or 'Quantity'.")
        return self._timestep_qt if kind == 'Quantity' else self._timestep_td

    def __repr__(self):
        return (f'DataTaker({self.read_files})\n\n'
                f'Test settings: {self.test_settings}')

    def mean(self, col):
        """
        Average the raw values on intervals where adjacent elements of col are
        equal.

        Parameters
        ----------
        col : {steady_state_time, Nss}
            The name of the column used to determine the intervals to compute
            the means.

        """
        dtk = deepcopy(self)
        rd = dtk.raw_data
        adjacent = (rd[col] != rd[col].shift()).cumsum()
        dtk.raw_data = rd.groupby([col, adjacent],
                          as_index=False, sort=False).mean()
        dtk.quantities = {}
        return dtk

    def _build_name_converter(self, filename):
        """
        Create a DataFrame to get the actual columns names
        in the DataTaker file.

        Parameters
        ----------
        filename : str, default 'name_conversions_UTF8.txt'
            The name of the DataTaker file.

        """

        # Read the label conversion table differently according to the OS
        nconv = pd.read_fwf(filename, comment='#',
                            widths=[12, 36, 20, 20, 5], index_col=0)
        nconv[nconv=='-'] = None
        self._name_converter = nconv

    def read(self, paths=None, initialdir='.', filetype=None, mode=None,
             overwrite=False):
        """
        Read a data file and assign it to the raw_data attribute.

        Parameters
        ----------
        paths : iterable of str or 'all', default None
            An iterable with the paths of the files to read. When set to
            'all', every file in initialdir is selected. If None
            is given, a dialog box will ask to select the files.
            Valid extensions are csv (.csv) and excel (.xlsx).
        initialdir : str, default '.'
            a string with the path of the directory in which the dialog
            box will open if no filename is specified.
        filetype : str, optional
            Extension of files to use for plotting (csv or excel).
            If not specified, files with both extension are used.
            Useful when `paths` is either 'all' or None.
        mode : {'heating', 'cooling'}, default None
            If specified, only values of the given mode are kept.
        overwrite : bool, default False
            If set to True, the read data will replace the data already present
            in the DataTaker, instead of appending it.

        """

        if filetype is not None:
            filetype = filetype.lstrip('.').lower().replace('xlsx', 'excel')
        if paths is None:
            # Display default files based on the specified filetype
            if filetype is None:
                filetypes = (('All files', '.*'), ('CSV', '.csv'),
                             ('Excel', '.xlsx'))
            elif filetype.lower() in ('csv', '.csv'):
                filetypes = (('CSV', '.csv'), ('All files', '.*'))
            elif filetype.lower() in ('excel', 'xlsx', '.xlsx'):
                filetypes = (('Excel', '.xlsx'), ('All files', '.*'))
            Tk().withdraw()  # remove tk window
            # Open dialog window in initialdir
            paths = askopenfilenames(initialdir=initialdir,
                                     title='Select input file',
                                     filetypes=filetypes)
            # Return if the Cancel button is pressed
            if paths in ((), ''):
                return None
        elif paths == 'all':  # take every file in initialdir
            filenames = listdir(initialdir)
            if filetype is None:
                paths = [f'{initialdir}/{filename}' for filename in filenames]
            else:
                extension = filetype.replace('excel', 'xlsx')
                if extension.lstrip('.') not in ('csv', 'xlsx'):
                    raise ValueError('invalid file extension')
                paths = [f'{initialdir}/{filename}' for filename in filenames
                         if filename.lower().endswith(extension)]
        elif isinstance(paths, str):  # only one path given
            paths = [paths]

        def encoding(file):
            """Check the encoding of a file."""

            with open(file, encoding='UTF8') as f:
                try:
                    next(f)
                except UnicodeDecodeError:
                    return 'ISO-8859-1'
                else:
                    return 'UTF8'

        def get_specific_mode_values(data, mode):
            col_name = self._name_converter.loc['refdir', 'col_names']
            valid_rows = data[col_name] == {'heating': 0, 'cooling': 1}[mode]
            return data[valid_rows].reset_index(drop=True)

        if overwrite:
            self.raw_data = None
            self.quantities = {}
        for i, path in enumerate(paths):
            _, extension = splitext(path.lower())
            if extension not in ('.csv', '.xlsx'):
                raise ValueError('invalid file extension')
            if filetype is None:
                ftype = {'.csv':'csv', '.xlsx':'excel'}[extension]
            # Define the reader function according to the file type
            call = 'read_' + ftype
            first_line = getattr(pd, call)(path,
                                           nrows=0, encoding=encoding(path))
            if any( word in list(first_line)[0] for word in
                ['load', 'aux', 'setpoint', '|', 'PdT'] ):
                # Print the test conditions if only one file
                if len(paths) == 1:
                    self.test_settings = list(first_line)[0]
                # Skip the first row containing the conditions
                raw_data = getattr(pd, call)(path, skiprows=1,
                                             encoding=encoding(path))
            else:
                try:
                    raw_data = getattr(pd, call)(path, encoding=encoding(path))
                except pd.errors.ParserError as e:
                    if str(e).startswith('Error tokenizing data. C error:'):
                        new_err_msg = f'{e}\nTest file: {path}'
                        raise pd.errors.ParserError(new_err_msg)
                    else:
                        raise e

            # Clean frequency values
            f_col_name = self._name_converter.loc['f', 'col_names']
            try:
                f = raw_data[f_col_name]
            except KeyError as e:
                if str(e) == "'FREQ raw (Hz)'":
                    try:
                        f_col_name = 'Compressor Frequency'
                        f = raw_data[f_col_name]
                    except KeyError:
                        raise e
                else:
                    raise e
            raw_data.loc[(raw_data[f_col_name] == 'UnderRange'), f_col_name] = 0
            raw_data[f_col_name] = raw_data[f_col_name].astype(float) / 2

            # Clean refrigerant flow rate values
            flow_col_name = self._name_converter.loc['flowrt_r', 'col_names']
            raw_data.loc[raw_data[f_col_name] == 0, flow_col_name] = 0

            raw_data['Timestamp'] = pd.to_datetime(
                raw_data['Timestamp']
            ).apply(lambda t: t.round('s'))
            start_timestamp = raw_data['Timestamp'].iloc[0]
            stop_timestamp = raw_data['Timestamp'].iloc[-1]
            test_duration = stop_timestamp - start_timestamp
            start_time = start_timestamp.strftime('%d/%m %H:%M')
            stop_time = stop_timestamp.strftime('{}%H:%M'.format(
                '%d/%m ' if test_duration > pd.Timedelta('1 day') else '')
            )
            raw_data['file_index'] = i
            raw_data['test_period'] = f'{start_time} - {stop_time}'
            raw_data['test_duration'] = test_duration
            old_f_label, new_f_label = 'Compressor Frequency', 'FREQ raw (Hz)'
            if (old_f_label in raw_data and new_f_label not in raw_data):
                raw_data = raw_data.rename(columns={old_f_label: new_f_label})
            if mode is not None:
                raw_data = get_specific_mode_values(raw_data, mode)
            if self.raw_data is None:
                self.raw_data = raw_data
            else:
                self.raw_data = pd.concat([self.raw_data, raw_data],
                                          sort=False).reset_index(drop=True)
            self.read_files.append(basename(path))

    def _set_timestep(self, kind='Timedelta'):
        """
        Return the duration between two consecutive data samples.

        Parameter
        ---------
        kind : 'Timedelta' or 'Quantity', default 'Timedelta'
            Specifiy the type of the object returned.

        Returns
        -------
        Pandas Timedelta, or Quantity

        """

        t0 = self.raw_data['Timestamp'].iloc[0]
        t1 = self.raw_data['Timestamp'].iloc[1]
        if kind == 'Timedelta':
            self._timestep_td = t1 - t0
        elif kind == 'Quantity':
            self._timestep_qt = (t1 - t0).seconds * self.ureg('seconds')
        else:
            raise ValueError("kind must be either 'Timedelta' or 'Quantity'.")

    def _array_to_slice(self, interval):
        if isinstance(interval, self.Q_):
            if not isinstance(interval.m, np.ndarray):
                interval = self.Q_([0, interval.m], interval.units)
            dt = self.get_timestep('Quantity')
            sl_args = interval.m_as('s') / dt.m_as('s')
            return slice(*(int(sl_arg) for sl_arg in sl_args))
        elif isinstance(interval, pd.Timedelta):
            return slice(0, int(interval / self.get_timestep('Timedelta')))
        else:
            raise TypeError('argument must be of type Timdelta of Quantity.')

    def _build_quantities(self, *quantities, **kwargs):
        """
        Add quantities to the DataTaker's quantities attribute,
        optionally returning them as Quantity objects.

        Parameters
        ----------
        *quantities : {'T{1-9}', 'h{1-9}', p{1-9}, phase{1-9}, 'Tin', 'Tout',
                       'Ts', 'Tr', 'RHr', 'RHs', 'wr', 'ws', 'Twbr', 'Twbs',
                       'hs', 'hx', 'hr', 'SHR', 'Tamb', 'Tdtk', 'pin', 'pout',
                       'RHout','Tout_db', 'refdir', 'Pfan_out', 'Pfan_in',
                       'Pa', 'Pb', 'Ptot', 'Qcond', 'Qev', 'Pcomp', 'Qc',
                       'Qcs', 'Qcl', 'f', 't', 'flowrt_r'}

        Example
        -------
        >>> dtk = vpa.DataTaker()
        >>> quantities = ('T1', 'T2', 'T3')
        >>> T1, T2, T3 = dtk._build_quantities(*quantities)

        """

        def properties(*args):
            return refproperties(*args, self._refrigerant)

        nconv = self._name_converter
        quantities = set(quantities)
        if not quantities: return
        # quantities are divided into 10 categories:
        #   air humidity ratios,
        #   wet-bulb temperatures,
        #   refrigerant pressures,
        #   refrigerant enthalpies,
        #   refrigerant phases,
        #   cooling capacities,
        #   those whose magnitude require a bit of cleaning,
        #   those depending upon other quantities to be computed,
        #   and those that can be taken 'as is' from the raw data.
        hum_ratios = quantities & {'ws', 'wr'}
        wet_bulbs = quantities & {'Twbs', 'Twbr'}
        pressures = quantities & {f'p{i+1}' for i in range(9)}
        enthalpies = (quantities
                        & ({f'h{i+1}' for i in range(9)} | {'hr', 'hx', 'hs'}))
        phases = quantities & {f'phase{i+1}' for i in range(9)}
        to_clean = quantities & {'RHr', 'RHs', 'SHR'}
        dependent = (quantities &
                            {'Qcond', 'Qev', 'Pcomp', 'Pel', 'Qloss_ev', 't'})
        cooling_cap = quantities & {'Qc', 'Qcs', 'Qcl'}
        as_is = (quantities - hum_ratios - wet_bulbs - pressures - enthalpies
                            - phases - to_clean - dependent - cooling_cap)

        refstate_error = 'The refrigerant state must be between 1 and 9.'
        p_atm = self.Q_('1 atm')

        interval = kwargs.pop('interval', slice(None))
        if not isinstance(interval, slice):
            interval = self._array_to_slice(interval)
        raw_data = self.raw_data.iloc[interval, :]
        for key, value in kwargs.items():
            raw_data = raw_data[raw_data[key] == value]
        if interval != slice(None):
            kwargs['interval'] = interval

        if enthalpies or dependent - {'Pel', 't'} or phases or pressures:
            ref_dir = self.get('refdir', **kwargs).magnitude
        if enthalpies or dependent - {'Pel', 't'}:
            # majority of 0 = heating, majority of 1 = cooling
            heating = np.count_nonzero(ref_dir) < len(ref_dir) / 2

        for HR in hum_ratios:
            hrstate = HR.strip('w')
            T, RH = self.get(f'T{hrstate} RH{hrstate}', **kwargs)
            p = p_atm.m_as('pascal')
            w = psychro('W', 'P', p, 'T', T.m_as('K'), 'RH', RH.m_as('ratio'))
            if hrstate == 's':
                wr = self.get('wr', **kwargs).m_as('kg/kg')
                w = np.where(w < wr, w, wr)
            self.quantities[HR] = self.Q_(w, label=f'$\omega_{{{hrstate}}}$',
                                             prop='absolute humidity',
                                             units='ratio').to('g/kg')

        for WB in wet_bulbs:
            wbstate = WB.strip('Twb')
            T, RH = self.get(f'T{wbstate} RH{wbstate}', **kwargs)
            p = p_atm.m_as('pascal')
            Twb = psychro('Twb', 'P', p, 'T', T.m_as('K'),
                                         'RH', RH.m_as('ratio'))
            if wbstate == 's':
                Twbr = self.get('Twbr', **kwargs).m_as('kelvin')
                Twb = np.where(Twb < Twbr, Twb, Twbr)
            self.quantities[WB] = self.Q_(Twb, units='kelvin').to('degC')
            self.quantities[WB].set_name('wet-bulb', f'$T_{{wb{wbstate}}}$')

        for pressure in pressures:
            state = int(pressure.strip('p'))
            if state in (1, 2):
                p = self.get(f"p{'in' if state == 1 else 'out'}", **kwargs)
            elif state in range(3, 10):
                pin, pout= self.get(f'pin pout', **kwargs)
                if state in (3, 4, 5, 6):
                    p = pin * ref_dir + pout * (1-ref_dir)
                else:
                    p = pin * (1-ref_dir) + pout * ref_dir
            else:
                raise ValueError(refstate_error)
            self.quantities[pressure] = self.Q_(p.m_as('kPa'), units='kPa')
            self.quantities[pressure].set_name('pressure', f'$p_{state}$')

        for enthalpy in enthalpies:
            state = enthalpy.strip('h')
            if state.isdigit():
                p, T = self.get(f'p{state} T{state}', **kwargs)
                if p.size != 0:
                    h = properties('H', 'P', p.m_as('Pa'), 'T', T.m_as('K'))
                else:
                    h = np.array([])
            elif state == 'x':
                (T, w), p = self.get(f'Tr ws', **kwargs), self.Q_('1 atm')

                h = psychro('H', 'T', T.m_as('K'), 'W', w.m_as('kg/kg'),
                                 'P', p.m_as('pascal'))
            else:
                T, RH = self.get(f'T{state} RH{state}', **kwargs)
                h = psychro('H', 'T', T.m_as('K'), 'RH', RH.m_as('ratio'),
                                 'P', p_atm.m_as('pascal'))
            self.quantities[enthalpy] = self.Q_(h, units='J/kg').to('kJ/kg')
            self.quantities[enthalpy].set_name('enthalpy', f'$h_{state}$')

        for ph in phases:
            state = int(ph.strip('phase'))
            pr = self.get(f'p{state}', **kwargs).m_as('pascal')
            Tr = self.get(f'T{state}', **kwargs).m_as('kelvin')
            self.quantities[ph] = self.Q_(
                np.array([phase('P', p, 'T', T, self._refrigerant)
                          for p, T in zip(pr, Tr)])
            )

        for quantity in to_clean & {'RHr', 'RHs'}:
            RH = raw_data[nconv.loc[quantity, 'col_names']].values
            RH[RH < 0] = 0
            RH[RH > 100] = 100
            self.quantities[quantity] = self.Q_(RH,
                label=nconv.loc[quantity, 'labels'],
                prop=nconv.loc[quantity, 'properties'],
                units=nconv.loc[quantity, 'units'])

        if 'SHR' in to_clean:
            hr = self.get('hr/kJ/kg', **kwargs).magnitude
            hx = self.get('hx/kJ/kg', **kwargs).magnitude
            hs = self.get('hs/kJ/kg', **kwargs).magnitude
            SHR = np.where(hr > hs, (hx - hs) / (hr - hs), 1)
            SHR[SHR < 0] = 0
            self.quantities['SHR'] = self.Q_(SHR, label='SHR', prop='ratio')

        ureg = self.ureg
        @ureg.wraps(ureg.joules/ureg.kg,
                    (ureg.joules/ureg.kg, None, None, ureg.Pa))
        def fix_enthalpy(h, phase, expected_phase, pressure_level):
            quality = {'gas': 1, 'liquid': 0}[expected_phase.lower()]
            wrong_phase = phase != expected_phase
            if np.any(wrong_phase) and pressure_level.size != 0:
                h[wrong_phase] = properties('H',
                                            'P', pressure_level[wrong_phase],
                                            'Q', quality)
            return h

        def split_props(q, states):
            quantities = self.get(' '.join(f'{q}{s}' for s in states), **kwargs)
            magnitudes = [quantity.magnitude for quantity in quantities]
            q_high, q_low = np.split(np.array(magnitudes), 2)
            units = self.get(f'{q}{states[0]}', **kwargs).units
            return self.Q_(q_high, units), self.Q_(q_low, units)

        for quantity in dependent - {'Pel', 't'}:
            states = {'Qcond': [4, 2, 6, 7], 'Qev': [9, 4, 6, 7],
                      'Pcomp': [2, 1], 'Qloss_ev': [1, 4]}[quantity]
            h_high, h_low = split_props('h', states)
            p_high, p_low = split_props('p', states)
            phase_high, phase_low = split_props('phase', states)
            fixed_h_high = fix_enthalpy(h_high, phase_high, 'gas', p_high)
            ep_low = 'liquid' if quantity in {'Qcond', 'Qev'} else 'gas'
            fixed_h_low = fix_enthalpy(h_low, phase_low, ep_low, p_low)
            dh = h_high - h_low
            if quantity in {'Qcond', 'Qev'}:
                dh = ref_dir * dh[1] + (1 - ref_dir) * dh[0]
            else:
                dh = dh[0] * (1 if quantity == 'Pcomp' else ref_dir)
            Q = self.get('flowrt_r', **kwargs) * dh
            label={'Qcond': '$ \\dot{Q}_{cond} $',
                   'Qev': '$ \\dot{Q}_{ev} $',
                   'Pcomp': '$ P_{comp} $',
                   'Qloss_ev': '$ \\dot{Q}_{loss,ev} $'}[quantity]
            prop = ('mechanical power' if quantity == 'Pcomp' else
                    'heat transfer rate')
            self.quantities[quantity] = self.Q_(Q.m_as('kW'), units='kW')
            self.quantities[quantity].set_name(prop, label)

        if 'Pel' in dependent:
            Pel = np.add(*self.get('Pa Pb', **kwargs))
            self.quantities['Pel'] = self.Q_(Pel.m, units=Pel.units).to('kW')
            self.quantities['Pel'].set_name('electrical power', '$P_{el}$')

        if 't' in dependent:
            timestep = self.get_timestep()
            samples_number = len(raw_data.index)
            time_in_seconds = np.arange(samples_number) * timestep.seconds
            self.quantities['t'] = self.Q_(time_in_seconds, units='seconds',
                                           label='$t$', prop='time')

        if cooling_cap:
            Qev, Pfan_in = self.get('Qev Pfan_in', **kwargs)
            Qc = (Qev - Pfan_in).m_as('kW')
            for Q in cooling_cap:
                sub = Q.replace('Qc', '').lower()
                if sub:  # compute SHR only if needed
                    SHR = self.get('SHR', **kwargs).magnitude
                SLfactor = {'s': SHR, 'l': 1 - SHR}.get(sub) if sub else 1
                self.quantities[Q] = self.Q_(Qc * SLfactor, units='kW',
                                             label=f'$\\dot Q_{{c{sub}}}$',
                                             prop='heat transfer rate')

        for quantity in as_is:
            try:
                magnitude = raw_data[nconv.loc[quantity, 'col_names']].values
            except KeyError:
                if quantity == 'Pfan_in':
                    magnitude = raw_data['Indoor Unit Fan Power (kW)'].values
                else:
                    raise
            self.quantities[quantity] = self.Q_(magnitude,
                label=nconv.loc[quantity, 'labels'],
                prop=nconv.loc[quantity, 'properties'],
                units=nconv.loc[quantity, 'units'])

    def get(self, variables, update=False, **kwargs):
        """
        Return specific quantities from a DataTaker as Quantity objects.

        All the specified quantities that are not yet in the DataTaker's
        quantities are added, then all the specified quantities are
        returned in the form of Quantity objects.

        Parameters
        ----------
        quantities : str with a combination of the following items,
                     separated by spaces
            {T1 T2 T3 T4 T5 T6 T7 T8 T9 Ts RHs ws Tr RHr wr Tin
             Tout Tamb Tdtk f RHout Tout_db refdir flowrt_r pin
             pout Pa Pb Pfan_out Pfan_in Ptot Qcond Qev Pcomp}
        update : boolean, default False
            If set to True, quantities already present in the
            `quantities` attribute will be overwritten.
        **kwargs
            Keyword arguments allow to return quantities corresponding
            only to certain group in raw_data.

        Returns
        -------
        xpint Quantity or iterable of xpint Quantity objects

        Examples
        --------
        >>> dtk = vpa.DataTaker()
        >>> T4, pout = dtk.get('T4 pout')

        >>> properties = 'T1 T2 T3 T4 T5 T6 T7'
        >>> T1, T2, T3, T4, T5, T6, T7 = dtk.get(properties)

        Get the properties only for the second specified file
        (if at least two were specified):

        >>> T4, pout = dtk.get('T4 pout', index_file=1)

        Get the properties for a specific test period:

        >>> period = '26/09 08:36 - 14:31'
        >>> T4, pout = dtk.get('T4 pout', test_period=period)

        """

        spec_units = {}
        quantities = variables.split()
        for i, variable in enumerate(variables.split()):
            if '/' in variable:
                quantity, unit = variable.split('/', 1)
                quantities[i] = quantity
                spec_units[quantity] = unit

        interval = kwargs.pop('interval', slice(None))
        if not isinstance(interval, slice):
            interval = self._array_to_slice(interval)
        kwargs['interval'] = interval
        if update or self._groups != kwargs:
            self.quantities = {}
            self._build_quantities(*set(quantities), **kwargs)
        else:
            # Only build quantities not already in the DataTaker's quantities
            self._build_quantities(*(set(quantities) - set(self.quantities)),
                                   **kwargs)
        self._groups = kwargs

        def update_units(quantity):
            return self.quantities[quantity].to(spec_units.get(quantity))

        # Return a Quantity if there is only one element in quantities
        if len(quantities) > 1:
            return (update_units(quantity) for quantity in quantities)
        else:
            return update_units(quantities[0])

        return result

    @ureg.wraps(None, (None, ureg.second))
    def set_steady_state_limits(self, limits):
        """
        Set the 'steady_state_time' column in raw_data according to the
        provided limits.

        Parameter
        ---------
        limits : Quantity with dimension [time]
            The steady-state time levels used to group measurements.
            To include measurements lower than the smallest value,
            add -numpy.inf as first element.
            To include measurements higher than the largest value,
            add numpy.inf as last element.

        Example
        -------
        >>> dtk = vaplac.DataTaker()
        >>> limits = np.array([5, 10, 40, np.inf]) * dtk.ureg('min')
        >>> dtk.set_steady_state_limits(limits)
        >>> dtk.plot('Qcond Pel', 'Tr Tout', groupby='steady_state_time')

        """

        timestep = self.get_timestep().seconds
        Nss = self.steady_state_steps_number()
        steady_state_time = Nss * timestep
        include_lb = limits[0] == -np.inf
        include_ub = limits[-1] == np.inf
        nb = len(limits) - 1

        def to_timedelta(limit):
            if limit == np.inf:
                return pd.Timedelta.max
            elif limit == -np.inf:
                return pd.Timedelta.min
            else:
                return pd.Timedelta(f'00:00:{limit}')

        def get_interval(td_limits, i):
            closed = 'neither' if i == 0 and include_lb else 'left'
            return pd.Interval(td_limits[i], td_limits[i+1], closed=closed)

        timedelta_limits = [to_timedelta(limit) for limit in limits]
        bins = [get_interval(timedelta_limits, i) for i in range(nb)]
        sst_bins = np.empty_like(steady_state_time, dtype=object)
        for i, binidx in enumerate(np.digitize(steady_state_time, limits)):
            out_of_bounds = binidx == nb + 1 or binidx == 0
            sst_bins[i] = None if out_of_bounds else bins[binidx - 1]
        self.raw_data['steady_state_time'] = sst_bins
        self.raw_data['Nss'] = Nss

    def plot(self, dependents='all', independents='t/minutes', groupby=None,
             colorbar=None, interval=slice(None), **kwargs):
        """
        Plot DataTaker's quantities against time.

        If no quantities are given, all the Quantity objects in the
        DataTaker's attribute `quantities` are plotted. Each quantity
        having an identical dimensionality is plotted in the same axis.

        Parameters
        ----------
        dependents : {'all', 'allsplit', 'allmerge'} or str, default 'all'
            All the dependent quantities to be plotted, separated by a
            space. Quantites to be plotted together must be grouped
            inside (), [] or {}. A specific unit can also be given to a
            quantity or a group, using the format quantity/unit.
        independents : str, default 't/minutes'
            All the independent quantities to be plotted, separated by a
            space. Independent quantities cannot be grouped together, as
            opposed to dependent ones.
        groupby : str, default None
            The groups that will be highlighted in the plots.
            If not None, dependent quantities cannot be grouped.
        **kwargs : see function vaplac.plot.

        Examples
        --------
        Unit specification rely on pint and is therefore really
        felxible. For exemple, use teraelectronvolt per nanosecond
        for power :

        >>> dtk = vpa.DataTaker()
        >>> dtk.plot('(T1 T2) (Qev Qcond)/TeV/ns', 'f/rpm, t/hour')

        Group by test period:

        >>> dtk.plot('Qev Qcond', groupby='test_period')

        """

        # Store in a list the arguments to pass
        # to the vaplac.plot function
        args = []
        dependents = 'allmerge' if dependents == 'all' else dependents
        colorbar_quantity = None

        # Define an iterator and an appender to add the right quantities
        # to the args list
        if dependents == 'allsplit':
            iterator = self.dependents.keys()
            appender = lambda arg: self.get(arg, interval=interval)
        elif dependents == 'allmerge':
            def gen():
                # Group dependents by property
                key = lambda q: self.dependents[q].prop
                for _, prop in groupby(sorted(self.dependents, key=key), key):
                    # Yield a list in any case, the appender will take
                    # care of the cases with only one element
                    yield [self.dependents[q] for q in prop]
            iterator = gen()
            appender = lambda arg: arg[0][interval] if len(arg) == 1 else arg[interval]
        elif any(delim in dependents for delim in ('(', '[', '{')):
            # Split but keep grouped quantities together
            iterator = [arg.strip('()')
                        for arg in re.findall(r'\([^\)]*\)|\S+', dependents)]
            # Distribute any unit specified over a group
            if ')/' in dependents:
                for i, arg in enumerate(iterator):
                    if arg.startswith('/'):
                        unit = arg[1:]
                        group = iterator[i-1]
                        iterator[i-1] = f'/{unit} '.join(group.split(' '))
                        iterator[i-1] += f'/{unit}'
                        del iterator[i]
            def appender(arg):
                if ' ' in arg:
                    return list(self.get(arg, interval=interval))
                else:
                    return self.get(arg, interval=interval)
        else:

            iterator = dependents.split()
            if groupby:

                def quantity_from_group(arg, groupby, key):
                    quantity = self.get(arg, **{groupby: key},
                                        interval=interval)
                    quantity.group = key
                    return quantity

                groupby_indices = self.raw_data.groupby(groupby).indices
                appender = lambda arg: [quantity_from_group(arg, groupby, key)
                                        for key in groupby_indices]
            else:
                appender = lambda arg: self.get(arg, interval=interval)

        for arg in iterator:
            args.append(appender(arg))

        if groupby:

            commons = [[quantity_from_group(common, groupby, key)
                        for key in groupby_indices]
                        for common in independents.split()]
            if colorbar:
                if len(groupby_indices) > 1:
                    err_msg = 'colorbar cannot be set with more than one group.'
                    raise ValueError(err_msg)
                key = list(groupby_indices.keys())[0]
                colorbar_quantity = self.get(colorbar, **{groupby:key},
                                             interval=interval)
        else:
            if colorbar:
                colorbar_quantity = self.get(colorbar)[interval]
            commons = [self.get(common, interval=interval)
                       for common in independents.split()]

        _plot(self, *args, commons=commons, colorbar=colorbar_quantity,
                    **kwargs)

    @ureg.wraps(None, (None, ureg.hertzs))
    def steady_state_steps_number(self, sd_limit=Q_('2 Hz')):
        """
        Return the number of time steps in steady-state.

        Parameter
        ---------
        sd_limit : Quantity with dimension [1/time], default 2 Hz.
            The standard deviation limit that the frequency should not exceed
            in order to stay in steady-state regime.

        Returns
        -------
        steps_number : ndarray
            An array with the steady-state time interval of each measurement.

        """

        frequency = self.get('f').m_as('Hz')
        mean = np.empty_like(frequency)
        var = np.empty_like(frequency)
        steps_number = np.ones_like(frequency)
        mean[0] = frequency[0]
        var[0] = 0
        buffer = 1
        for i, f in enumerate(frequency[1:], 1):
            mean[i] = (buffer*mean[i-1] + f) / (buffer + 1)
            var[i] = ((buffer*(var[i-1] + mean[i-1]**2) + f**2) / (buffer + 1)
                      - mean[i]**2)
            buffer += 1
            if sqrt(var[i]) > sd_limit:  # standard deviation higher than 2 Hz
                mean[i] = f
                var[i] = 0
                steps_number[i-buffer:i] = buffer
                if np.isnan(buffer):
                    set_trace()
                buffer = 0
        steps_number[-buffer:] = buffer
        return steps_number

    def validate(self, show_data=False):
        """
        Perform data checks implemented in vaplac.sauroneye.

        If no abnormalities are detected, the message 'No warnings' is
        displayed. Otherwise, the corresponding warnings will be given.

        Parameters
        ----------
        show_data : boolean, default False
            If set to True, the quantities involved in the checks
            resulting in a warning are plotted.

        Example
        -------
        >>> dtk = vpa.DataTaker()
        >>> dtk.validate(show_data=True)

        """
        schema = {check: {'check_with': getattr(sauroneye, check)}
                  for check in dir(sauroneye) if check.endswith('check')}
        v = Validator(schema)
        if v.validate({check: self for check in schema}):
            print('No warnings')
        else:
            n_warn = len(v.errors)
            if n_warn > 1:
                print(f'There are {n_warn} warnings:')
                for i, warning in enumerate(v.errors.values()):
                    print(' ', i+1, warning[0])
            else:
                warn = list(v.errors.values())[0][0]
                print('Warning:', warn[0].lower() + warn[1:] if warn else warn)

            if show_data:
                checkargs = sauroneye._checkargs
                args = ' '.join(checkargs[check] for check in v.errors)
                self.plot(args)

    @ureg.wraps(None, (None, ureg.minute))
    def has_steady_state(self, time_limit=Q_('30 minutes')):
        """
        Check whether the test file associated with the DataTaker has
        steady-state values.

        Parameter
        ---------
        time_limit : Quantity, default 30 minutes.
            If there is at least one steady-state period as long
            as time_limit or longer, the method returns True,
            otherwise it returns False.

        Returns
        -------
        bool

        """
        Nss = self.steady_state_steps_number()
        dts = Nss * self.get_timestep('Quantity').m_as('minutes')
        return np.any(dts >= time_limit)
